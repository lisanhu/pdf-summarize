Tree-of-Thoughts, a Huge Leap for ChatGPT Toward Human-level Thinking
Shaping How AI Thinks
Ignacio de Gregorio
Ignacio de Gregorio

¬∑
Follow

7 min read
¬∑
May 29
285


11





Source: Author with MidJourney inspired by Alize Razell
In the realm of human cognition, we often refer to two distinct systems of thinking: ‚ÄúSystem 1‚Äù, which is fast, instinctive, and emotional, and ‚ÄúSystem 2‚Äù, which is slower, more deliberative, and more logical.

These two systems work in tandem to help us navigate the complexities of our world.

Large Language Models (LLMs), like ChatGPT, have made significant strides in mimicking ‚ÄúSystem 1‚Äù thinking, generating human-like text with impressive speed and accuracy.

However, when it comes to the more complex, contemplative ‚ÄúSystem 2‚Äù thinking, these models have historically fallen short... dramatically.

But this could be changing, as a revolutionary new approach, developed by researchers from Princeton University and Google DeepMind, promises to change that by achieving impressive success in tasks where ChatGPT is failing miserably today.

As we delve deeper into the workings of this technique and its implications, you‚Äôll discover why Tree-of-Thoughts could be the key to transforming language models into the general-purpose problem solvers of the future.

This new insight was previously covered in my free newsletter, where I deep dive into the fascinating world of AI by providing you with the latest innovations in an easy-going, only 5 minutes a week, fun read.

üèùSubscribe belowüèù to change your perspective of AI and, in the meantime, harness the power to change your life below:

TheTechOasis
The newsletter to stay ahead of the curve in AI
thetechoasis.beehiiv.com

A More Human AI
It never ceases to surprise me how powerful Language Models are despite having one of the simplest AI structures ever.

Beautifully simple, works wonderfully always‚Ä¶ well, almost.

One simple task, hundreds of applications
Large Language Models (LLMs) like ChatGPT have been designed to generate text by making word-level decisions one by one in a left-to-right fashion.

This approach, reminiscent of the fast, automatic, unconscious mode of human thinking known as ‚ÄúSystem 1‚Äù, has proven effective for a wide range of tasks. Summarization, comparison‚Ä¶ the out-of-the-box applications of LLMs are many.

But this simple mechanism is not without its limitations, as it can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role.

Tasks were our ‚ÄúSystem 2‚Äù, the conscious mode in humans and a cornerstone in the field of cognitive psychology, excels at.

In other words, the deliberate mode of thinking that we engage in when faced with complex decisions or problems. It allows us to consider multiple options, weigh the pros and cons, and make informed decisions.

But how can LLMs achieve this level of thinking?

Organizing thoughts in ‚Äúthe human way‚Äù
ToT introduces a new framework for language model inference that generalizes over the popular ‚ÄúChain-of-Thought‚Äù (CoT) approach.

But what is CoT prompting?

CoT is a very popular way of prompting AI language models. In very simple terms, it‚Äôs simply asking the model to take its time to answer.

For instance, let‚Äôs say you want a language model to solve a simple brain teaser.

If you simply ask it the question without CoT, this happens:


Source: Author with GPT-4
As you can see, the model fails gruesomely.

Now, if you we apply a CoT strategy by asking the model to take its time, this happens:


Now the model got it right.

But why does this work?

Although we aren‚Äôt fully prepared to explain why CoT works, researchers are considering two possible options:

‚ÄúModels need tokens to think‚Äù: As Andrej Karpathy described in the last Microsoft conference, the more tokens the answer has, the stronger the answer is, as the next word prediction is grounded on more data.
More computational power: Alternatively, the longer the answer, the more computational effort the model is putting into answering your question. More computational power means better answers.
Bottom line, although this isn‚Äôt fully proven, the longer the answer, the better.

But how does ToT differ from CoT?

ChatGPT, we need you to think before you answer
In simple terms, ToT enables exploration over coherent units of text, or ‚Äúthoughts‚Äù, that serve as intermediate steps toward problem-solving.

As we can see in the image below, ToT frames problems as a search over a tree, where each node is a state representing a partial solution with the input and the sequence of thoughts so far.


Source: Princeton & Google DeepMind
It allows LLMs to perform deliberate decision-making by considering multiple different reasoning paths and self-evaluating every choice to decide the next course of action.

In layman‚Äôs terms, it‚Äôs an iterative process over the same ‚Äústep-by-step reasoning‚Äù of CoT, but applying deliberate evaluation over every intermediate step, or thought.

But how does ToT improve over the status quo?

A new way of thinking for LLMs
As I said earlier, ToT represents the first-ever approach to allowing LLMs to truly imitate human ‚ÄúSystem 2‚Äù thinking.

The current approach to Large Language Models (LLMs) is fundamentally different, as the model, unless asked to, will rush into answering directly.

Put simply, unless told otherwise, ChatGPT is a default ‚ÄúSystem 1‚Äù thinker.

But ToT does things differently.

In a way, ToT can be thought of as an evolution of techniques like CoT and CoT-SC, the latter of which is simply sampling several CoTs and calculating a majority vote on the best option, merging them into, literally, a tree of thoughts that combines the two things:

It forces the LLM to reason every step by generating intermediate thoughts that will drive its decision-making
It performs self-evaluation, in which the own model evaluates its own thoughts
However, self-evaluation will work differently depending on the tree-search algorithm the model uses:

Breadth-First Search (BFS): This algorithm maintains a set of the most promising states at each step. In simpler terms, BFS explores all the thoughts at the current level before moving on to the next level.
This approach ensures that all possible paths are considered at each step.

Depth-First Search (DFS): This algorithm explores the most promising state first until the final output is reached or the state evaluator deems it impossible to solve the problem from the current state. In the latter case, the subtree from the current state is pruned.
DFS goes as deep as possible into the tree of thoughts (through one unique path) before backtracking if it reaches an impossible conclusion, until it finds the best one.

All in all sounds very promising. But how was this technique tested and what were the amazing results it achieved?

Results That Will Make You Think, and Dream
If you read between the lines, we‚Äôre beginning to create prompts that allow these models to solve ever more so complex problems.

The problems that rule our complex world.

But what type of problems could we be referring to?

Games and a Threat to creative writers
The researchers tested ToT technique on three novel tasks that require non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.

Here were the results:

Game of 24: This is a mathematical card game where the objective is to find a way to manipulate four integers so that the end result is 24. For instance, for the numbers 4, 7, 8, and 8, a possible solution could be 8*(7 ‚Äî (8/4)). The researchers used this game to test the ability of ToT to perform mathematical reasoning and search.
In this task, while GPT-4 with CoT prompting only solved 4% of tasks, the Tree-of-Thoughts technique achieved a success rate of 74%, a 1750% improvement.

2. Creative Writing: In this task, the input was four random sentences, and the output should be a coherent passage with four paragraphs that end in the four input sentences respectively. This task was designed to challenge creative thinking and high-level planning.

Specifically, in a blind study comparing the coherency of passages generated by ToT and the traditional approach, humans preferred ToT in 41 out of 100 passage pairs, while only preferring the traditional approach in 21 (the other 38 pairs were found ‚Äúsimilarly coherent‚Äù).

Not really impressive, but a win is a win, right?

3. Mini Crosswords: This final task involved solving 5x5 mini crossword puzzles. The ToT technique achieved a success rate of 78% in terms of correct letters, 60% in terms of correct words, and 20% in terms of correct games.

In comparison, the traditional approach (standard prompting) obtained 0 correct games. Yes, 0.

A dawn of a new era?
As we stand on the brink of a new era in artificial intelligence, the Tree-of-Thoughts technique emerges as a beacon of innovation.

It represents a significant departure from the traditional approach of Large Language Models, introducing a new way for these models to approach problem-solving.

By mimicking the conscious, deliberative mode of human thinking, ToT allows LLMs to evaluate multiple reasoning paths and make more informed decisions.

The results achieved by the researchers using this technique are a testament to its potential. We‚Äôre talking about results that blow state-of-the-art prompting techniques out of the water.

These successes are not just victories in their own right; they are stepping stones towards a future where LLMs can be used as general-purpose problem solvers.

But the ToT technique is more than just a promising avenue of research. It‚Äôs a glimpse into the future of artificial intelligence.

A future where LLMs are not just tools for generating human-like text, but partners in solving complex problems. A future where the line between human cognition and artificial intelligence becomes increasingly blurred.

And as we look forward to the dawn of general-purpose problem-solving AI solutions, we can‚Äôt help but be excited about the possibilities that lie ahead.